{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travel Recommender using Google Gemini\n",
    "\n",
    "This notebook uses Google's Gemini API to generate detailed travel recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get api keys\n",
    "https://aistudio.google.com/app/api-keys\n",
    "\n",
    "\n",
    "Different list of models which google has\n",
    "https://ai.google.dev/gemini-api/docs/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the openai package?\n",
    "\n",
    "It's known as a Python Client Library.\n",
    "\n",
    "It's nothing more than a wrapper around making this exact call to the http endpoint.\n",
    "\n",
    "It just allows you to work with nice Python code instead of messing around with janky json objects.\n",
    "\n",
    "But that's it. It's open-source and lightweight. Some people think it contains OpenAI model code - it doesn't!\n",
    "\n",
    "\n",
    "OpenAI's Chat Completions API was so popular, that the other model providers created endpoints that are identical.\n",
    "\n",
    "They are known as the \"OpenAI Compatible Endpoints\".\n",
    "\n",
    "For example, google made one here: https://ai.google.dev/gemini-api/docs/openai\n",
    "\n",
    "And OpenAI decided to be kind: they said, hey, you can just use the same client library that we made for GPT. We'll allow you to specify a different endpoint URL and a different key, to use another provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from openai import OpenAI\n",
    "openai = OpenAI()\n",
    "\n",
    "# Note: Make sure to install required packages:\n",
    "# pip install python-dotenv beautifulsoup4 google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system prompt for travel recommendations\n",
    "\n",
    "system_prompt = \"\"\"Generate a detailed travel recommendation. Include the following information: \\\n",
    "    1. **Overview**: A brief introduction to the destination, highlighting its unique characteristics and appeal.\\\n",
    "    2. **Cost Breakdown**: - Average cost of accommodation (budget, mid-range, luxury options).\\\n",
    "        - Estimated daily expenses (food, transportation, activities).\\\n",
    "        - Total estimated cost for a typical 5-day trip for a solo traveler and a family of four.\\\n",
    "    3. **Best Time to Visit**: \\\n",
    "        - Identify the peak, shoulder, and off-peak seasons.\\\n",
    "        - Highlight the pros and cons of visiting during each season, including weather conditions and local events.\\\n",
    "    4. **Hidden Gems**: - List at least five lesser-known attractions or experiences that are must-sees.\\\n",
    "        - Provide a brief description of each hidden gem, including why it is special and any tips for visiting.\\\n",
    "    5. **Local Tips**: \\\n",
    "        - Suggest local customs or etiquette that travelers should be aware of.\\\n",
    "        - Recommend local dishes to try and where to find them. Make sure the recommendation is engaging and informative, appealing to a diverse range of travelers.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not google_api_key:\n",
    "    print(\"No API key was found - please be sure to add your key to the .env file, and save the file! Or you can skip the next 2 cells if you don't want to use Gemini\")\n",
    "elif not google_api_key.startswith(\"AIz\"):\n",
    "    print(\"An API key was found, but it doesn't start AIz\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(user_prompt):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt }\n",
    "    ]\n",
    "\n",
    "def recommender():\n",
    "    response = gemini.chat.completions.create(\n",
    "        model = \"gemini-2.5-flash-lite\",\n",
    "        messages = messages_for(f\"Create a travel recommendation for couple in Srilanka\")\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result():\n",
    "    recommendendation = recommender()\n",
    "    display(Markdown(recommendendation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Ollama to be free and local instead of OpenAI\n",
    "Ollama allows you to run models locally; it provides an OpenAI compatible API on your machine.\n",
    "There's no API key for Ollama; there's no third party with your credit card, so no need for any kind of key.\n",
    "\n",
    "If you're new to Ollama, install it by following the instructions here: https://ollama.com\n",
    "Then in a Cursor Terminal, do ollama run llama3.2 to chat with Llama 3.2\n",
    "BEWARE: do not use llama3.3 or llama4 - these are massive models not designed for home computing! They will fill up your disk.\n",
    "Then:\n",
    "\n",
    "!ollama pull llama3.2\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"anything\")\n",
    "response = ollama.chat.completions.create(model=\"llama3.2\", messages=[{\"role\":\"user\", \"content\": \"what is 2+2?\"}])\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "Using the popular service OpenRouter which has an easier billing process instead of OpenAI\n",
    "OpenRouter is very convenient: it gives you free access to many models, and easy access with small upfront to paid models.\n",
    "\n",
    "Sign up at https://openrouter.ai\n",
    "Add the minimum upfront balance as needed\n",
    "Add your key as OPENROUTER_API_KEY to your .env file\n",
    "Then:\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "openrouter = OpenAI(base_url=OPENROUTER_BASE_URL, api_key=openrouter_api_key)\n",
    "response = openrouter.chat.completions.create(model=\"openai/gpt-4.1-nano\", messages=[{\"role\":\"user\", \"content\": \"what is 2+2?\"}])\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
